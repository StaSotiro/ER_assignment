{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>QD Inc</td>\n",
       "      <td>San Diego,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11578 Sorrento Valley Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AS Argon, JG Hannoosh</td>\n",
       "      <td>Phil. Mag,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Initiation of crazes in polystyrene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>GH Hansen, LL Wetterberg, H SjÃ¶strÃ¶m, O NorÃ©n</td>\n",
       "      <td>The Histochemical Journal,</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>Immunogold labelling is a quantitative method ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TM Hammett, P Harmon, W Rhodes</td>\n",
       "      <td>see</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Burden of Infectious Disease Among Inmates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>JR Cogdell</td>\n",
       "      <td>NEW DIRECTIONS FOR TEACHING AND LEARNING,</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>The Role of Faculty Advising in Science and En...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           authors  \\\n",
       "0   1                                            QD Inc   \n",
       "1   2                             AS Argon, JG Hannoosh   \n",
       "2   3  GH Hansen, LL Wetterberg, H SjÃ¶strÃ¶m, O NorÃ©n   \n",
       "3   4                    TM Hammett, P Harmon, W Rhodes   \n",
       "4   5                                        JR Cogdell   \n",
       "\n",
       "                                       venue    year  \\\n",
       "0                                 San Diego,     NaN   \n",
       "1                                 Phil. Mag,     NaN   \n",
       "2                 The Histochemical Journal,  1992.0   \n",
       "3                                        see     NaN   \n",
       "4  NEW DIRECTIONS FOR TEACHING AND LEARNING,  1995.0   \n",
       "\n",
       "                                               title  \n",
       "0                         11578 Sorrento Valley Road  \n",
       "1                Initiation of crazes in polystyrene  \n",
       "2  Immunogold labelling is a quantitative method ...  \n",
       "3  The Burden of Infectious Disease Among Inmates...  \n",
       "4  The Role of Faculty Advising in Science and En...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./erdata.csv', sep=';')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NAs with empty strings to allow concatentation\n",
    "data.authors = data.authors.fillna(\"\")\n",
    "data.venue = data.venue.fillna(\"\")\n",
    "data.year = data.year.astype(str)\n",
    "data.year = data.year.fillna(\"\")\n",
    "data.title = data.title.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"fullText\"] = data[\"authors\"] + \" \" + data[\"venue\"]+ \" \" + data[\"year\"]+ \" \" + data[\"title\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's make sure we have no NAs\n",
    "sum(data.fullText.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the blocks / Vectorizer\n",
    "<br>\n",
    "For this solution we are using SckitLearn's [Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), which allows us to extract features from text like inputs. <br>\n",
    "In order to do that we are transforming the data to strings, and concatenating it to a new column, later passed for extraction. <br>\n",
    "The process generates a 2D array, with each row referencing an entity from the original Data passed, and each column having 1 if a respective feature belongs to this entity, 0 otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default Vectorizer transforms strings to lowercase ==> https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data[\"fullText\"])\n",
    "feat = vectorizer.get_feature_names_out()\n",
    "xArray = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Features found: 92603\n",
      "\n",
      "\n",
      "Sample output:\n",
      "['abstinence' 'abstinent' 'abstr' 'abstrac' 'abstract' 'abstracted'\n",
      " 'abstracting' 'abstraction' 'abstractions' 'abstractness' 'abstracts'\n",
      " 'abstractâ' 'abstracuon' 'absurd' 'absurdities' 'abt' 'abts' 'abu'\n",
      " 'abugov' 'abuknesha' 'abundance' 'abundances' 'abundant' 'abuse' 'abused'\n",
      " 'abuser' 'abusers' 'abuses' 'abusive' 'abuzenadah' 'abwasser' 'aby'\n",
      " 'abyssal' 'abyzov' 'abã' 'ac' 'ac0' 'ac0851' 'ac095' 'aca' 'acad'\n",
      " 'academe' 'academia' 'academic' 'academically' 'academician'\n",
      " 'academicpress' 'academics' 'academicâ' 'academies' 'academy' 'acadian'\n",
      " 'acadimic' 'acanthopterygii' 'acar' 'acarine' 'acarol' 'acarregui'\n",
      " 'acaseforredundantarraysofinexpensive' 'acc' 'accapp03' 'accc' 'acce'\n",
      " 'accelaration' 'accelerate' 'accelerated' 'accelerating' 'acceleration'\n",
      " 'accelerator' 'accelerators' 'accelerograms' 'accelerometer'\n",
      " 'accelerometers' 'accelrys' 'accents' 'accentuated' 'accept'\n",
      " 'acceptability' 'acceptable' 'acceptance' 'accepted' 'accepting'\n",
      " 'acceptor' 'accepts' 'acces' 'access' 'accessed' 'accesses'\n",
      " 'accessexecute' 'accessforthemasses' 'accessibility' 'accessible'\n",
      " 'accessing' 'accessingnearbycopies' 'accession' 'accessions'\n",
      " 'accessmethodsfor' 'accessory'\n",
      " 'accesspathelectioninarelationaldatabasemanagement'\n",
      " 'accesspathselectioninarelational']\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Features found: \" + str(len(feat)) + \"\\n\\n\")\n",
    "print(\"Sample output:\")\n",
    "print(feat[2000:2100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findElements(xArray,data, i):\n",
    "    objList = []\n",
    "    \n",
    "    for j in range(len(xArray)):\n",
    "        itemVector = xArray[j]\n",
    "        \n",
    "        # Check if the item contains the feature, if yes, append its ID\n",
    "        if itemVector[i] == 1:\n",
    "            objList.append(data.iloc[j].id)\n",
    "    \n",
    "    return objList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "# Let's create a structure containing the blocks\n",
    "# The format will be FeatureName : [Array Of Item IDs that contain the Feature]\n",
    "bar = progressbar.ProgressBar(maxval=len(feat), \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "dictMap = {}\n",
    "for i in range(len(feat)):\n",
    "    bar.update(i)\n",
    "    dictMap[feat[i]] = findElements(xArray, data, i)\n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove blocks with < 2 size\n",
    "dictKeys = [x for x in dictMap.keys()]\n",
    "for blk in dictKeys:\n",
    "    if len(dictMap[blk]) < 2:\n",
    "        del dictMap[blk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1527, 15546, 30821, 33340]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print an example of the 'academics' feature\n",
    "dictMap['academics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66879\n",
      "66879\n",
      "92603\n",
      "92603\n"
     ]
    }
   ],
   "source": [
    "print(len(X.toarray()))\n",
    "print(len(data))\n",
    "print(len(X.toarray()[0]))\n",
    "print(len(feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Comparisons: 3779840\n"
     ]
    }
   ],
   "source": [
    "# In this exmaple we know the entities' structure. So each comparison would be comparing EntityA FieldA w/ EntityB FieldA, etc. \n",
    "# This let's us assume that a comparison between two entities would cost us 4 field comparisons. \n",
    "# If we did not know the schema, we would need to to compare all fields between each other. This brings up the number to #NumberOfEntityAKeys x #NumberOfEntityBKeys. E.g. Entity A has 4 fields and Entity B has 5 -> A comparison would be 4x5=20\n",
    "\n",
    "compCost = 4\n",
    "sum=0\n",
    "for blk in dictMap:\n",
    "    for i in range(len(blk)):\n",
    "        sum = sum + compCost*i\n",
    "print(\"Total Comparisons: \" + str(sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Building Graph\n",
    "In order to build a graph, we are creating a series of edges in the form of \n",
    "[NodeFrom, NodeTo, Weight] <br>\n",
    "\n",
    "A target Node is a node that exists in the same block as the original Node <br>\n",
    "In order to build this graph we will:<br>\n",
    "* Iterate over the dictionary we built earlier\n",
    "* For each of its elements add edges and weights between the Entities (0 if it's the first occurence, +1 if it already exists)\n",
    "<!-- end of the list -->\n",
    "This allows us to create a graph faster than a double for loop<br>\n",
    "There is one issue here: When in one block contains nodes 123 and 321 and another one contains 321 and 123 then with this implementation there will be an arc created for 123 -> 321 and when the second block is checked, the new arc 321->123 will be created, instead of updating the first one. <br>\n",
    "How do we easily solve this? - By sorting the blocks' arrays / Thankfully, since the package worked iteratively and the initial Entities were sorted, the blocks had sorted values appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1527, 15546, 30821, 33340]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictMap['academics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "# Constructor\n",
    "    def __init__(self, num_of_nodes, directed=False):\n",
    "        self.m_num_of_nodes = num_of_nodes\n",
    "        self.m_directed = directed\n",
    "        \n",
    "        # Different representations of a graph\n",
    "        self.m_list_of_edges = []\n",
    "\t\n",
    "    # Add edge to a graph\n",
    "    def add_edge(self, node1, node2, weight=1):        \n",
    "        # Add the edge from node1 to node2 - If the edge exists, increase the weight by 1\n",
    "        found = 0\n",
    "        for i in range(len(self.m_list_of_edges)):\n",
    "            if((self.m_list_of_edges[i][0]==node1) & (self.m_list_of_edges[i][0]==node2) ):\n",
    "                found=1\n",
    "                self.m_list_of_edges[i][2] = self.m_list_of_edges[i][2] + 1\n",
    "        if(found == 0):\n",
    "            self.m_list_of_edges.append([node1, node2, weight])\n",
    "        \n",
    "    def get_edges(self):\n",
    "        return self.m_list_of_edges\n",
    "    \n",
    "    def set_edges(self, edges):\n",
    "        self.m_list_of_edges = edges\n",
    "\n",
    "\t# Print a graph representation\n",
    "    def print_edge_list(self, thres=0):\n",
    "        num_of_edges = len(self.m_list_of_edges)\n",
    "        if(thres!=0):\n",
    "            num_of_edges = thres\n",
    "        for i in range(thres):\n",
    "            print(\"edge \", i+1, \": \", self.m_list_of_edges[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(len(data))\n",
    "\n",
    "# loop over all keys\n",
    "for blk in dictMap:\n",
    "\n",
    "    # for each key loop over the entity IDs\n",
    "    for i in range(len(blk)):\n",
    "        for j in range(i+1, len(blk)-1):\n",
    "            graph.add_edge(blk[i], blk[j])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove edges w/ Weight < 2\n",
    "edges = []\n",
    "for edge in graph.get_edges():\n",
    "    if edge[2] >= 2:\n",
    "        edges.append(edge) \n",
    "\n",
    "graph.set_edges(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new number of comparisons is: NumberOfGraphEdges x ComparisonCost\n",
    "compCost = 4\n",
    "\n",
    "print(\"Total Comparisons: \" + str(len(graph.get_edges() * 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JaccardSimilarity(title1, title2):\n",
    "    print(\"Comparing: \",title1, title2 )\n",
    "    title1Words = title1.split()\n",
    "    title2Words = title1.split()\n",
    "    union = list(set(title1Words) + set(title2Words))\n",
    "    inter = set(title1Words).intersection(title2Words)\n",
    "    return (union / inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example\n",
    "\n",
    "JaccardSimilarity(data[3, \"title\"], data[4, \"title\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
